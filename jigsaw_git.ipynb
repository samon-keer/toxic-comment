{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c702a451",
   "metadata": {},
   "source": [
    "# Hate_speech and fake_news_labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db0c7639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, auc\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve,roc_curve,roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c03bc7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "#load train and test data\n",
    "df1=pd.read_csv(r'/Users/sk/Documents/Liverpool/jigsaw-toxic-comment-classification-challenge/train.csv/trains.csv')\n",
    "df2=pd.read_csv(r'/Users/sk/Documents/Liverpool/jigsaw-toxic-comment-classification-challenge/test.csv/test.csv')\n",
    "df3=pd.read_csv(r'/Users/sk/Documents/Liverpool/jigsaw-toxic-comment-classification-challenge/test_labels.csv/test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d11fc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140445</th>\n",
       "      <td>ef86792ec6d8ac8b</td>\n",
       "      <td>acceptable, as far as anyone can know</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52269</th>\n",
       "      <td>8be27c1f932ceee6</td>\n",
       "      <td>Friendly notification\\nPlease note that Wikipe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "140445  ef86792ec6d8ac8b              acceptable, as far as anyone can know   \n",
       "52269   8be27c1f932ceee6  Friendly notification\\nPlease note that Wikipe...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "140445      0             0        0       0       0              0  \n",
       "52269       0             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the train data\n",
    "df1.sample(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d1ba9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target labels (only the training set has labels)\n",
    "X = df1['comment_text']\n",
    "y = df1[df1.columns[2:]]\n",
    "\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cd2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test and evaluate the model\n",
    "#X_test = df2['comment_text']\n",
    "\n",
    "# Prepare the test labels for evaluation\n",
    "test_labels = df3[df3.iloc[:,2:].sum(axis=1) != -6] \n",
    "X_test = df2[df2['id'].isin(test_labels['id'])]['comment_text']\n",
    "y_test = test_labels.drop(columns=['id'])\n",
    "#z_test = test_labels[test_labels.columns[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f94663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               153164\n",
       "toxic            153164\n",
       "severe_toxic     153164\n",
       "obscene          153164\n",
       "threat           153164\n",
       "insult           153164\n",
       "identity_hate    153164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d76405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119105    Geez, are you forgetful!  We've already discus...\n",
       "131631    Carioca RFA \\n\\nThanks for your support on my ...\n",
       "125326    \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...\n",
       "111256    Pseudoscience category? \\n\\nI'm assuming that ...\n",
       "83590     (and if such phrase exists, it would be provid...\n",
       "                                ...                        \n",
       "121162    \"  Would you claim them to be part of the \"\"ig...\n",
       "34019     The lyrics is found in the German version, so ...\n",
       "83938     Encyclopedia Titanica references do not source...\n",
       "78687              A silly fat cow who won't leave me alone\n",
       "127984    Shazbot now your lieing you already stated you...\n",
       "Name: comment_text, Length: 31915, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b0caa",
   "metadata": {},
   "source": [
    "# SVM (linear) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf02948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53598b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extraction and model pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('svm', OneVsRestClassifier(LinearSVC(multi_class='ovr')))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bd9b7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC for toxic: 0.83\n",
      "Accuracy for toxic: 0.96\n",
      "Recall for toxic: 0.68\n",
      "Precision for toxic: 0.86\n",
      "Confusion Matrix for toxic:\n",
      "[[28533   326]\n",
      " [  975  2081]]\n",
      "\n",
      "Training model for severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC for severe_toxic: 0.64\n",
      "Accuracy for severe_toxic: 0.99\n",
      "Recall for severe_toxic: 0.27\n",
      "Precision for severe_toxic: 0.54\n",
      "Confusion Matrix for severe_toxic:\n",
      "[[31519    75]\n",
      " [  233    88]]\n",
      "\n",
      "Training model for obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC for obscene: 0.84\n",
      "Accuracy for obscene: 0.98\n",
      "Recall for obscene: 0.69\n",
      "Precision for obscene: 0.89\n",
      "Confusion Matrix for obscene:\n",
      "[[30056   144]\n",
      " [  526  1189]]\n",
      "\n",
      "Training model for threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC for threat: 0.62\n",
      "Accuracy for threat: 1.00\n",
      "Recall for threat: 0.24\n",
      "Precision for threat: 0.58\n",
      "Confusion Matrix for threat:\n",
      "[[31828    13]\n",
      " [   56    18]]\n",
      "\n",
      "Training model for insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC for insult: 0.78\n",
      "Accuracy for insult: 0.97\n",
      "Recall for insult: 0.57\n",
      "Precision for insult: 0.79\n",
      "Confusion Matrix for insult:\n",
      "[[30063   238]\n",
      " [  692   922]]\n",
      "\n",
      "Training model for identity_hate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC for identity_hate: 0.64\n",
      "Accuracy for identity_hate: 0.99\n",
      "Recall for identity_hate: 0.28\n",
      "Precision for identity_hate: 0.73\n",
      "Confusion Matrix for identity_hate:\n",
      "[[31590    31]\n",
      " [  211    83]]\n",
      "\n",
      "CPU times: user 19.8 s, sys: 298 ms, total: 20.1 s\n",
      "Wall time: 20.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train a separate SVM model for each label\n",
    "svm_models = []\n",
    "for label in y:\n",
    "    print(f'Training model for {label}')\n",
    "    pipeline.fit(X_train_split, y_train_split[label])\n",
    "    svm_models.append(pipeline.named_steps['svm'])\n",
    "\n",
    "    # Validate the model\n",
    "    svm_y_val_pred = pipeline.predict(X_val_split)\n",
    "    print(f'ROCAUC for {label}: {roc_auc_score(y_val_split[label], svm_y_val_pred):.2f}')\n",
    "    print(f'Accuracy for {label}: {accuracy_score(y_val_split[label], svm_y_val_pred):.2f}')\n",
    "    print(f'Recall for {label}: {recall_score(y_val_split[label], svm_y_val_pred):.2f}')\n",
    "    print(f'Precision for {label}: {precision_score(y_val_split[label], svm_y_val_pred):.2f}')\n",
    "    print(f'Confusion Matrix for {label}:\\n{confusion_matrix(y_val_split[label], svm_y_val_pred)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2811b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for toxic on test set: 0.38\n",
      "Recall for toxic on test set: 0.35\n",
      "Precision for toxic on test set: 0.20\n",
      "Confusion Matrix for toxic on test set:\n",
      "[[    0 88167  1019]\n",
      " [    0 57803    85]\n",
      " [    0  5785   305]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for severe_toxic on test set: 0.41\n",
      "Recall for severe_toxic on test set: 0.40\n",
      "Precision for severe_toxic on test set: 0.16\n",
      "Confusion Matrix for severe_toxic on test set:\n",
      "[[    0 88167  1019]\n",
      " [    0 63297   314]\n",
      " [    0   291    76]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for obscene on test set: 0.39\n",
      "Recall for obscene on test set: 0.35\n",
      "Precision for obscene on test set: 0.19\n",
      "Confusion Matrix for obscene on test set:\n",
      "[[    0 88167  1019]\n",
      " [    0 60128   159]\n",
      " [    0  3460   231]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threat on test set: 0.41\n",
      "Recall for threat on test set: 0.36\n",
      "Precision for threat on test set: 0.14\n",
      "Confusion Matrix for threat on test set:\n",
      "[[    0 88167  1019]\n",
      " [    0 63397   370]\n",
      " [    0   191    20]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for insult on test set: 0.40\n",
      "Recall for insult on test set: 0.36\n",
      "Precision for insult on test set: 0.19\n",
      "Confusion Matrix for insult on test set:\n",
      "[[    0 88167  1019]\n",
      " [    0 60406   145]\n",
      " [    0  3182   245]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for identity_hate on test set: 0.41\n",
      "Recall for identity_hate on test set: 0.45\n",
      "Precision for identity_hate on test set: 0.20\n",
      "Confusion Matrix for identity_hate on test set:\n",
      "[[    0 88167  1019]\n",
      " [    0 63124   142]\n",
      " [    0   464   248]]\n",
      "\n",
      "CPU times: user 15.6 s, sys: 144 ms, total: 15.7 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict and evaluate on the test set\n",
    "svm_predictions = []\n",
    "for i, label in enumerate (y.columns):\n",
    "    svm_y_test_pred = svm_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n",
    "    print(f'Accuracy for {label} on test set: {accuracy_score(y_test[label], svm_y_test_pred):.2f}')\n",
    "    print(f'Recall for {label} on test set: {recall_score(y_test[label], svm_y_test_pred, average=\"macro\"):.2f}')\n",
    "    print(f'Precision for {label} on test set: {precision_score(y_test[label], svm_y_test_pred, average= \"macro\"):.2f}')\n",
    "    print(f'Confusion Matrix for {label} on test set:\\n{confusion_matrix(y_test[label], svm_y_test_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b9ef68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output DataFrame with 'id' column and predicted labels\n",
    "output_svm_df = df2[['id','comment_text']].copy()\n",
    "for i, label in enumerate(y.columns):\n",
    "    output_svm_df[label] = svm_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c5e4a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_svm_df.to_csv('/Users/sk/Documents/Liverpool/svm_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff55a83",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee9c9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dfdad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extraction and model pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('svc', OneVsRestClassifier(SVC(kernel='linear')))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f759d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for toxic\n",
      "ROCAUC for toxic: 0.83\n",
      "Accuracy for toxic: 0.96\n",
      "Recall for toxic: 0.66\n",
      "Precision for toxic: 0.89\n",
      "Confusion Matrix for toxic:\n",
      "[[28620   239]\n",
      " [ 1040  2016]]\n",
      "\n",
      "Training model for severe_toxic\n",
      "ROCAUC for severe_toxic: 0.52\n",
      "Accuracy for severe_toxic: 0.99\n",
      "Recall for severe_toxic: 0.04\n",
      "Precision for severe_toxic: 0.76\n",
      "Confusion Matrix for severe_toxic:\n",
      "[[31590     4]\n",
      " [  308    13]]\n",
      "\n",
      "Training model for obscene\n",
      "ROCAUC for obscene: 0.85\n",
      "Accuracy for obscene: 0.98\n",
      "Recall for obscene: 0.70\n",
      "Precision for obscene: 0.89\n",
      "Confusion Matrix for obscene:\n",
      "[[30053   147]\n",
      " [  521  1194]]\n",
      "\n",
      "Training model for threat\n",
      "ROCAUC for threat: 0.58\n",
      "Accuracy for threat: 1.00\n",
      "Recall for threat: 0.16\n",
      "Precision for threat: 0.63\n",
      "Confusion Matrix for threat:\n",
      "[[31834     7]\n",
      " [   62    12]]\n",
      "\n",
      "Training model for insult\n",
      "ROCAUC for insult: 0.78\n",
      "Accuracy for insult: 0.97\n",
      "Recall for insult: 0.57\n",
      "Precision for insult: 0.80\n",
      "Confusion Matrix for insult:\n",
      "[[30077   224]\n",
      " [  696   918]]\n",
      "\n",
      "Training model for identity_hate\n",
      "ROCAUC for identity_hate: 0.58\n",
      "Accuracy for identity_hate: 0.99\n",
      "Recall for identity_hate: 0.15\n",
      "Precision for identity_hate: 0.82\n",
      "Confusion Matrix for identity_hate:\n",
      "[[31611    10]\n",
      " [  249    45]]\n",
      "\n",
      "CPU times: user 27min 57s, sys: 6.43 s, total: 28min 3s\n",
      "Wall time: 28min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train a separate SVM model for each label\n",
    "svc_models = []\n",
    "for label in y:\n",
    "    print(f'Training model for {label}')\n",
    "    pipeline.fit(X_train_split, y_train_split[label])\n",
    "    svc_models.append(pipeline.named_steps['svc'])\n",
    "\n",
    "    # Validate the model\n",
    "    svc_y_val_pred = pipeline.predict(X_val_split)\n",
    "    print(f'ROCAUC for {label}: {roc_auc_score(y_val_split[label], svc_y_val_pred):.2f}')\n",
    "    print(f'Accuracy for {label}: {accuracy_score(y_val_split[label], svc_y_val_pred):.2f}')\n",
    "    print(f'Recall for {label}: {recall_score(y_val_split[label], svc_y_val_pred):.2f}')\n",
    "    print(f'Precision for {label}: {precision_score(y_val_split[label], svc_y_val_pred):.2f}')\n",
    "    print(f'Confusion Matrix for {label}:\\n{confusion_matrix(y_val_split[label], svc_y_val_pred)}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d406922b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for toxic on test set: 0.38\n",
      "Recall for toxic on test set: 0.34\n",
      "Precision for toxic on test set: 0.20\n",
      "Confusion Matrix for toxic on test set:\n",
      "[[    0 88572   614]\n",
      " [    0 57846    42]\n",
      " [    0  5907   183]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for severe_toxic on test set: 0.41\n",
      "Recall for severe_toxic on test set: 0.37\n",
      "Precision for severe_toxic on test set: 0.15\n",
      "Confusion Matrix for severe_toxic on test set:\n",
      "[[    0 88572   614]\n",
      " [    0 63426   185]\n",
      " [    0   327    40]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for obscene on test set: 0.39\n",
      "Recall for obscene on test set: 0.34\n",
      "Precision for obscene on test set: 0.18\n",
      "Confusion Matrix for obscene on test set:\n",
      "[[    0 88572   614]\n",
      " [    0 60196    91]\n",
      " [    0  3557   134]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threat on test set: 0.41\n",
      "Recall for threat on test set: 0.35\n",
      "Precision for threat on test set: 0.14\n",
      "Confusion Matrix for threat on test set:\n",
      "[[    0 88572   614]\n",
      " [    0 63551   216]\n",
      " [    0   202     9]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for insult on test set: 0.40\n",
      "Recall for insult on test set: 0.35\n",
      "Precision for insult on test set: 0.19\n",
      "Confusion Matrix for insult on test set:\n",
      "[[    0 88572   614]\n",
      " [    0 60480    71]\n",
      " [    0  3273   154]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for identity_hate on test set: 0.41\n",
      "Recall for identity_hate on test set: 0.41\n",
      "Precision for identity_hate on test set: 0.20\n",
      "Confusion Matrix for identity_hate on test set:\n",
      "[[    0 88572   614]\n",
      " [    0 63205    61]\n",
      " [    0   548   164]]\n",
      "\n",
      "CPU times: user 4min 21s, sys: 1.02 s, total: 4min 22s\n",
      "Wall time: 4min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict and evaluate on the test set\n",
    "svc_predictions = []\n",
    "for i, label in enumerate (y.columns):\n",
    "    svc_y_test_pred = svc_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n",
    "    print(f'Accuracy for {label} on test set: {accuracy_score(y_test[label], svc_y_test_pred):.2f}')\n",
    "    print(f'Recall for {label} on test set: {recall_score(y_test[label], svc_y_test_pred, average=\"macro\"):.2f}')\n",
    "    print(f'Precision for {label} on test set: {precision_score(y_test[label], svc_y_test_pred, average= \"macro\"):.2f}')\n",
    "    print(f'Confusion Matrix for {label} on test set:\\n{confusion_matrix(y_test[label], svc_y_test_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4844a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output DataFrame with 'id' column and predicted labels\n",
    "output_svc_df = df2[['id','comment_text']].copy()\n",
    "for i, label in enumerate(y.columns):\n",
    "    output_svc_df[label] = svm_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "871c3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_svc_df.to_csv('/Users/sk/Documents/Liverpool/svc_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ce8e7",
   "metadata": {},
   "source": [
    "# logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc9e4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8757b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extraction and model pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('logisticRegression', OneVsRestClassifier(LogisticRegression(C=1e5, max_iter=100000))) #penalty, default = l2, ridge\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ad47b5b",
   "metadata": {},
   "source": [
    "pipeline.predict_proba(X_val_split)[:,1] #Probability of flag==1 for all validation rows\n",
    "pipeline.predict_proba(X_val_split)[:,0] #Probability of flag==0 for all validation rows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad1490ae",
   "metadata": {},
   "source": [
    "pipeline.predict_proba(X_val_split)[:,1].sum()/len(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99c090fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for toxic\n",
      "ROCAUC for toxic: 0.83\n",
      "Accuracy for toxic: 0.94\n",
      "Recall for toxic: 0.68\n",
      "Precision for toxic: 0.72\n",
      "Confusion Matrix for toxic:\n",
      "[[28065   794]\n",
      " [  983  2073]]\n",
      "\n",
      "Training model for severe_toxic\n",
      "ROCAUC for severe_toxic: 0.66\n",
      "Accuracy for severe_toxic: 0.98\n",
      "Recall for severe_toxic: 0.33\n",
      "Precision for severe_toxic: 0.17\n",
      "Confusion Matrix for severe_toxic:\n",
      "[[31083   511]\n",
      " [  216   105]]\n",
      "\n",
      "Training model for obscene\n",
      "ROCAUC for obscene: 0.82\n",
      "Accuracy for obscene: 0.96\n",
      "Recall for obscene: 0.66\n",
      "Precision for obscene: 0.65\n",
      "Confusion Matrix for obscene:\n",
      "[[29581   619]\n",
      " [  586  1129]]\n",
      "\n",
      "Training model for threat\n",
      "ROCAUC for threat: 0.65\n",
      "Accuracy for threat: 0.99\n",
      "Recall for threat: 0.30\n",
      "Precision for threat: 0.14\n",
      "Confusion Matrix for threat:\n",
      "[[31709   132]\n",
      " [   52    22]]\n",
      "\n",
      "Training model for insult\n",
      "ROCAUC for insult: 0.76\n",
      "Accuracy for insult: 0.95\n",
      "Recall for insult: 0.53\n",
      "Precision for insult: 0.55\n",
      "Confusion Matrix for insult:\n",
      "[[29602   699]\n",
      " [  753   861]]\n",
      "\n",
      "Training model for identity_hate\n",
      "ROCAUC for identity_hate: 0.66\n",
      "Accuracy for identity_hate: 0.98\n",
      "Recall for identity_hate: 0.33\n",
      "Precision for identity_hate: 0.17\n",
      "Confusion Matrix for identity_hate:\n",
      "[[31167   454]\n",
      " [  198    96]]\n",
      "\n",
      "CPU times: user 3min 37s, sys: 17.2 s, total: 3min 54s\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train a separate LogisticRegression model for each label\n",
    "logistic_models = []\n",
    "for label in y.columns:\n",
    "    print(f'Training model for {label}')\n",
    "    pipeline.fit(X_train_split, y_train_split[label])\n",
    "    logistic_models.append(pipeline.named_steps['logisticRegression'])\n",
    "\n",
    "    # Validate the model\n",
    "    log_y_val_pred = pipeline.predict(X_val_split)\n",
    "    print(f'ROCAUC for {label}: {roc_auc_score(y_val_split[label], log_y_val_pred):.2f}')\n",
    "    print(f'Accuracy for {label}: {accuracy_score(y_val_split[label], log_y_val_pred):.2f}')\n",
    "    print(f'Recall for {label}: {recall_score(y_val_split[label], log_y_val_pred):.2f}')\n",
    "    print(f'Precision for {label}: {precision_score(y_val_split[label], log_y_val_pred):.2f}')\n",
    "    print(f'Confusion Matrix for {label}:\\n{confusion_matrix(y_val_split[label], log_y_val_pred)}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66d584ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for toxic on test set: 0.38\n",
      "Recall for toxic on test set: 0.36\n",
      "Precision for toxic on test set: 0.17\n",
      "Confusion Matrix for toxic on test set:\n",
      "[[    0 86323  2863]\n",
      " [    0 56976   912]\n",
      " [    0  5548   542]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for severe_toxic on test set: 0.41\n",
      "Recall for severe_toxic on test set: 0.40\n",
      "Precision for severe_toxic on test set: 0.15\n",
      "Confusion Matrix for severe_toxic on test set:\n",
      "[[    0 86323  2863]\n",
      " [    0 62235  1376]\n",
      " [    0   289    78]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for obscene on test set: 0.39\n",
      "Recall for obscene on test set: 0.36\n",
      "Precision for obscene on test set: 0.16\n",
      "Confusion Matrix for obscene on test set:\n",
      "[[    0 86323  2863]\n",
      " [    0 59191  1096]\n",
      " [    0  3333   358]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threat on test set: 0.41\n",
      "Recall for threat on test set: 0.38\n",
      "Precision for threat on test set: 0.14\n",
      "Confusion Matrix for threat on test set:\n",
      "[[    0 86323  2863]\n",
      " [    0 62350  1417]\n",
      " [    0   174    37]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for insult on test set: 0.39\n",
      "Recall for insult on test set: 0.36\n",
      "Precision for insult on test set: 0.16\n",
      "Confusion Matrix for insult on test set:\n",
      "[[    0 86323  2863]\n",
      " [    0 59467  1084]\n",
      " [    0  3057   370]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for identity_hate on test set: 0.41\n",
      "Recall for identity_hate on test set: 0.44\n",
      "Precision for identity_hate on test set: 0.16\n",
      "Confusion Matrix for identity_hate on test set:\n",
      "[[    0 86323  2863]\n",
      " [    0 62044  1222]\n",
      " [    0   480   232]]\n",
      "\n",
      "CPU times: user 15.7 s, sys: 179 ms, total: 15.9 s\n",
      "Wall time: 16.3 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict and evaluate on the test set\n",
    "predictions = []\n",
    "for i, label in enumerate (y.columns):\n",
    "    log_y_test_pred = logistic_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n",
    "    print(f'Accuracy for {label} on test set: {accuracy_score(y_test[label], log_y_test_pred):.2f}')\n",
    "    print(f'Recall for {label} on test set: {recall_score(y_test[label], log_y_test_pred, average=\"macro\"):.2f}')\n",
    "    print(f'Precision for {label} on test set: {precision_score(y_test[label], log_y_test_pred, average= \"macro\"):.2f}')\n",
    "    print(f'Confusion Matrix for {label} on test set:\\n{confusion_matrix(y_test[label], log_y_test_pred)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94cc7edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(log_y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "283429b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output DataFrame with 'id' column and predicted labels\n",
    "output_log_df = df2[['id','comment_text']].copy()\n",
    "for i, label in enumerate(y.columns):\n",
    "    output_log_df[label] = logistic_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "625eb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_log_df.to_csv('/Users/sk/Documents/Liverpool/log_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d3552",
   "metadata": {},
   "source": [
    "# Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "628ccc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8caa32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature extraction and model pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('multinomialNB', OneVsRestClassifier(MultinomialNB()))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "568a064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for toxic\n",
      "ROCAUC for toxic: 0.75\n",
      "Accuracy for toxic: 0.95\n",
      "Recall for toxic: 0.51\n",
      "Precision for toxic: 0.92\n",
      "Confusion Matrix for toxic:\n",
      "[[28731   128]\n",
      " [ 1493  1563]]\n",
      "\n",
      "Training model for severe_toxic\n",
      "ROCAUC for severe_toxic: 0.55\n",
      "Accuracy for severe_toxic: 0.99\n",
      "Recall for severe_toxic: 0.10\n",
      "Precision for severe_toxic: 0.73\n",
      "Confusion Matrix for severe_toxic:\n",
      "[[31582    12]\n",
      " [  289    32]]\n",
      "\n",
      "Training model for obscene\n",
      "ROCAUC for obscene: 0.75\n",
      "Accuracy for obscene: 0.97\n",
      "Recall for obscene: 0.50\n",
      "Precision for obscene: 0.91\n",
      "Confusion Matrix for obscene:\n",
      "[[30116    84]\n",
      " [  864   851]]\n",
      "\n",
      "Training model for threat\n",
      "ROCAUC for threat: 0.50\n",
      "Accuracy for threat: 1.00\n",
      "Recall for threat: 0.00\n",
      "Precision for threat: 0.00\n",
      "Confusion Matrix for threat:\n",
      "[[31840     1]\n",
      " [   74     0]]\n",
      "\n",
      "Training model for insult\n",
      "ROCAUC for insult: 0.70\n",
      "Accuracy for insult: 0.97\n",
      "Recall for insult: 0.41\n",
      "Precision for insult: 0.83\n",
      "Confusion Matrix for insult:\n",
      "[[30164   137]\n",
      " [  960   654]]\n",
      "\n",
      "Training model for identity_hate\n",
      "ROCAUC for identity_hate: 0.52\n",
      "Accuracy for identity_hate: 0.99\n",
      "Recall for identity_hate: 0.03\n",
      "Precision for identity_hate: 0.71\n",
      "Confusion Matrix for identity_hate:\n",
      "[[31617     4]\n",
      " [  284    10]]\n",
      "\n",
      "CPU times: user 18.4 s, sys: 273 ms, total: 18.6 s\n",
      "Wall time: 18.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train a separate MultinomialNaiveBayes model for each label\n",
    "naive_bayes_models = []\n",
    "for label in y.columns:\n",
    "    print(f'Training model for {label}')\n",
    "    pipeline.fit(X_train_split, y_train_split[label])\n",
    "    naive_bayes_models.append(pipeline.named_steps['multinomialNB'])\n",
    "\n",
    "    # Validate the model\n",
    "    nb_y_val_pred = pipeline.predict(X_val_split)\n",
    "    print(f'ROCAUC for {label}: {roc_auc_score(y_val_split[label], nb_y_val_pred):.2f}')\n",
    "    print(f'Accuracy for {label}: {accuracy_score(y_val_split[label], nb_y_val_pred):.2f}')\n",
    "    print(f'Recall for {label}: {recall_score(y_val_split[label], nb_y_val_pred):.2f}')\n",
    "    print(f'Precision for {label}: {precision_score(y_val_split[label], nb_y_val_pred):.2f}')\n",
    "    print(f'Confusion Matrix for {label}:\\n{confusion_matrix(y_val_split[label], nb_y_val_pred)}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92b1e87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for toxic on test set: 0.38\n",
      "Recall for toxic on test set: 0.33\n",
      "Precision for toxic on test set: 0.21\n",
      "Confusion Matrix for toxic on test set:\n",
      "[[    0 89111    75]\n",
      " [    0 57888     0]\n",
      " [    0  6063    27]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for severe_toxic on test set: 0.42\n",
      "Recall for severe_toxic on test set: 0.35\n",
      "Precision for severe_toxic on test set: 0.20\n",
      "Confusion Matrix for severe_toxic on test set:\n",
      "[[    0 89111    75]\n",
      " [    0 63602     9]\n",
      " [    0   349    18]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for obscene on test set: 0.39\n",
      "Recall for obscene on test set: 0.34\n",
      "Precision for obscene on test set: 0.22\n",
      "Confusion Matrix for obscene on test set:\n",
      "[[    0 89111    75]\n",
      " [    0 60286     1]\n",
      " [    0  3665    26]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for threat on test set: 0.42\n",
      "Recall for threat on test set: 0.34\n",
      "Precision for threat on test set: 0.15\n",
      "Confusion Matrix for threat on test set:\n",
      "[[    0 89111    75]\n",
      " [    0 63743    24]\n",
      " [    0   208     3]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for insult on test set: 0.40\n",
      "Recall for insult on test set: 0.34\n",
      "Precision for insult on test set: 0.22\n",
      "Confusion Matrix for insult on test set:\n",
      "[[    0 89111    75]\n",
      " [    0 60550     1]\n",
      " [    0  3401    26]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for identity_hate on test set: 0.41\n",
      "Recall for identity_hate on test set: 0.34\n",
      "Precision for identity_hate on test set: 0.21\n",
      "Confusion Matrix for identity_hate on test set:\n",
      "[[    0 89111    75]\n",
      " [    0 63262     4]\n",
      " [    0   689    23]]\n",
      "\n",
      "CPU times: user 15.7 s, sys: 124 ms, total: 15.8 s\n",
      "Wall time: 16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predict and evaluate on the test set\n",
    "predictions = []\n",
    "for i, label in enumerate (y.columns):\n",
    "    nb_y_test_pred = naive_bayes_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n",
    "    print(f'Accuracy for {label} on test set: {accuracy_score(y_test[label], nb_y_test_pred):.2f}')\n",
    "    print(f'Recall for {label} on test set: {recall_score(y_test[label], nb_y_test_pred, average=\"macro\"):.2f}')\n",
    "    print(f'Precision for {label} on test set: {precision_score(y_test[label], nb_y_test_pred, average= \"macro\"):.2f}')\n",
    "    print(f'Confusion Matrix for {label} on test set:\\n{confusion_matrix(y_test[label], nb_y_test_pred)}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5263e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output DataFrame with 'id' column and predicted labels\n",
    "output_NB_df = df2[['id','comment_text']].copy()\n",
    "for i, label in enumerate(y.columns):\n",
    "    output_NB_df[label] = naive_bayes_models[i].predict(pipeline.named_steps['tfidf'].transform(X_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bce1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_NB_df.to_csv('/Users/sk/Documents/Liverpool/nb_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c202a7",
   "metadata": {},
   "source": [
    "# Evaluate models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f407a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/sk/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance for training\n",
    "model_names = ['svm_models', 'svc_models', 'logistic_models', 'naive_bayes_models']\n",
    "accuracies = [[accuracy_score(y_val_split[label], svm_y_val_pred)], [accuracy_score(y_val_split[label], svc_y_val_pred)],\n",
    "              [accuracy_score(y_val_split[label], log_y_val_pred)], [accuracy_score(y_val_split[label], nb_y_val_pred)]]\n",
    "precisions = [[precision_score(y_val_split[label], svm_y_val_pred)], [precision_score(y_val_split[label], svc_y_val_pred)],\n",
    "              [precision_score(y_val_split[label], log_y_val_pred)], [precision_score(y_val_split[label], nb_y_val_pred)]]\n",
    "recalls = [[recall_score(y_val_split[label], svm_y_val_pred)], [recall_score(y_val_split[label], svc_y_val_pred)],\n",
    "              [recall_score(y_val_split[label], log_y_val_pred)], [recall_score(y_val_split[label], nb_y_val_pred)]]\n",
    "roc_auc = [[roc_auc_score(y_val_split[label], svm_y_val_pred)], [roc_auc_score(y_val_split[label], svc_y_val_pred)],\n",
    "              [roc_auc_score(y_val_split[label], log_y_val_pred)], [roc_auc_score(y_val_split[label], nb_y_val_pred)]]\n",
    "\n",
    "# Evaluate model performance for predictions\n",
    "model_names = ['svm_models', 'svc_models', 'logistic_models', 'naive_bayes_models']\n",
    "accuracies_pred = [[accuracy_score(y_test[label], svm_y_test_pred)], [accuracy_score(y_test[label], svc_y_test_pred)],\n",
    "              [accuracy_score(y_test[label], log_y_test_pred)], [accuracy_score(y_test[label], nb_y_test_pred)]]\n",
    "precisions_pred = [[precision_score(y_test[label], svm_y_test_pred,average='macro')], [precision_score(y_test[label], svc_y_test_pred,average='macro')],\n",
    "              [precision_score(y_test[label], log_y_test_pred,average='macro')], [precision_score(y_test[label], nb_y_test_pred,average='macro')]]\n",
    "recalls_pred = [[recall_score(y_test[label], svm_y_test_pred,average='macro')], [recall_score(y_test[label], svc_y_test_pred,average='macro')],\n",
    "              [recall_score(y_test[label], log_y_test_pred,average='macro')], [recall_score(y_test[label], nb_y_test_pred, average='macro')]]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7afa73ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores\n",
      "             Model             Accuracy             Precision                 Recall              ROC_AUC\n",
      "        svm_models [0.9924173586088046]  [0.7280701754385965]    [0.282312925170068] [0.6406662820088346]\n",
      "        svc_models [0.9918846937176876]  [0.8181818181818182]  [0.15306122448979592]  [0.576372489478382]\n",
      "   logistic_models [0.9795707347642174] [0.17454545454545456]  [0.32653061224489793]  [0.656086532522626]\n",
      "naive_bayes_models [0.9909760300798998]  [0.7142857142857143] [0.034013605442176874] [0.5169435536144821]\n",
      "__________________________________________________________________________\n",
      "Prediction scores\n",
      "             Model             Accuracy             Precision                Recall\n",
      "        svm_models [0.4137525789349978]  [0.1973237636645179] [0.44869003840984817]\n",
      "        svc_models [0.4137329920869134] [0.20346865669267133]  [0.4097909652260694]\n",
      "   logistic_models  [0.406596850434828]  [0.1568572430714416]  [0.4355091415343882]\n",
      "naive_bayes_models   [0.41318456034055] [0.21293327843653087]   [0.344080048557834]\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store train scores\n",
    "train_results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies,\n",
    "    'Precision': precisions,\n",
    "    'Recall': recalls,\n",
    "    'ROC_AUC': roc_auc\n",
    "})\n",
    "\n",
    "# Create a DataFrame to store prediction scores\n",
    "pred_results_df = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Accuracy': accuracies_pred,\n",
    "    'Precision': precisions_pred,\n",
    "    'Recall': recalls_pred,\n",
    "})\n",
    "\n",
    "print('Train scores')\n",
    "print(train_results_df.to_string(index=False))\n",
    "\n",
    "print('__________________________________________________________________________')\n",
    "\n",
    "print('Prediction scores')\n",
    "print(pred_results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c294926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of label 1 using SVM model is: 1409.00\n",
      "Count of label 0 using SVM model is: 151755.00\n",
      "Count of label 1 using SVC model is: 839.00\n",
      "Count of label 0 using SVC model is: 152325.00\n",
      "Count of label 1 using Logistic Regression model is: 4317.00\n",
      "Count of label 0 using Logistic Regression model is: 148847.00\n",
      "Count of label 1 using MultinomialNB model is: 102.00\n",
      "Count of label 0 using MultinomialNB model is: 153062.00\n"
     ]
    }
   ],
   "source": [
    "#output count\n",
    "print(f'Count of label 1 using SVM model is: {np.sum((svm_y_test_pred)==1):.2f}')\n",
    "print(f'Count of label 0 using SVM model is: {np.sum((svm_y_test_pred)==0):.2f}')\n",
    "print(f'Count of label 1 using SVC model is: {np.sum((svc_y_test_pred)==1):.2f}') \n",
    "print(f'Count of label 0 using SVC model is: {np.sum((svc_y_test_pred)==0):.2f}')\n",
    "print(f'Count of label 1 using Logistic Regression model is: {np.sum((log_y_test_pred)==1):.2f}')\n",
    "print(f'Count of label 0 using Logistic Regression model is: {np.sum((log_y_test_pred)==0):.2f}')\n",
    "print(f'Count of label 1 using MultinomialNB model is: {np.sum((nb_y_test_pred)==1):.2f}')\n",
    "print(f'Count of label 0 using MultinomialNB model is: {np.sum((nb_y_test_pred)==0):.2f}')\n",
    "\n",
    "#print(f'Confusion Matrix for {label} on test set:\\n{confusion_matrix(y_test[label], nb_y_test_pred)}\\n')\n",
    " #print(f'Precision for {label} on test set: {precision_score(y_test[label], nb_y_test_pred, average= \"macro\"):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
